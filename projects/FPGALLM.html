<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>FPGA LLM - Vishal Moorjani</title>
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <main>
        <h1>FPGA LLM</h1>

        <article class="blog-post">
            <div class="date">June 26, 2025</div>
            <p> Afternoon: I've been thinking about this waveforms stuff wrong. My issue was that I couldn't get x11 to work, so I 
                couldn't get any GUIs to work. But, I don't need to use x11. I can just download the vcd file, and then see it 
                on my compter. So I'm just using GTKWave to open the file and I can see all the signals I need. I haven't quite figured out 
                what to put in the waves.tcl file so I can get the ight signals in my waveform, but that is something I can figue out I'm sure. 
                Also, while going though the docs I found that they have an hdk/sdk project. I'm not sure if I can use this to 
                write the host code. If I can, then it's not a big deal that I can't co-simulate. Should spend time on this.
            </p>
            <p> Night: I'm actually quite silly. So, VCD files can't store unpacked arrays, which the matrices are. So, 
                they weren't showing up in the waveform. I spent too long trying to figure out the right way to structure 
                my tcl file before realising this. Now, I have Vivado on my computer. So, I don't need to work with 
                VCD files. So, the same way I download the VCD file, I can just download the WDB file which stores 
                everything, unpacked arrays and all, and just use XSIM on my computer to view it like I normally would. 
                Dissapointing that I didn't think of this earlier. I'll spend the rest of tonight figuring out 
                how to write host code. 
            </p>
        </article>

        <article class="blog-post">
            <div class="date">June 25, 2025</div>
            <p> I just wanted to wrap up the Int4 matmul stuff completely, so I've spent some more time on it today. The way it 
                works right now is that there is a control register at 0x0, and then 0x4 onwards is matrix A, then matrix B's address
                starts from wherever matrix A will end (since it is parameterised), and similarly there is matrix C. You can fill 
                the registers (control or for each element) with the values you want using AXI transactions and OCL, and then you 
                can signal to start computation using the control register. You can then poll one of the status bits to see if it's done, 
                and read back the result from matrix C, once again using AXI transactions. Now I'm going to instantiate it in the top level,
                and write a quick test bench to see if it works. If it does, I'll spend the rest of the day figuring out waveforms. 
                It really sucks not being able to run the co-simulation yet because testing this in C would have been such a breeze. Oh well.
            </p>
        </article>

        <article class="blog-post">
            <div class="date">June 24, 2025</div>
            <p> I spent all day today working on matmul, and understanding how to use the HBM from the examples they've provided.
                I also looked into why vivado isn't working, and why I can't get stuff to work with ForwardX11 on. I don't have 
                much more clarity on this, but at least things are moving along on the actual hardware. I'm sure there will be something 
                in Python that will allow me to generate better, interactive waveforms if I need them. Tomorrow I will work with HBM. 
                I will also spend time with SmolLM, and see exactly what the matrix dimensions are to know exactly what I need. 
            </p>
        </article>

        <article class="blog-post">
            <div class="date">June 23, 2025</div>
            <p> Afternoon: Progress! I am getting the co-simulation test to run, but I am still getting an error. 
                Also, I was going through this blog to see where I started from, and I noticed that it looks so much nicer
                with the pictures and stuff and it sucks that I don't have any to really show right now. Hopefully, I will have some soon.
                But, spending this extra day was helpful because I might actually be able to get the co-simulation to work. But, if I don't 
                I'm not putting any more time towards it right now. I'm going to move onto matmul tomorrow whether I can get it to work or not.
            </p>
            <p> Evening: I'm having issues where some of the function calls are not placed in an SV scope, and that seems to be the
                issue. The part that I am confused about, is I have exactly what they do. I've been using the dram_hbm_dma example they provide as ground truth to get co-simulation to work. I'm starting
                to think that maybe the example they've provided is wrong. I should have probably run this before I started following it, 
                but to be fair in their docs they've said that this is where one should look for co-simulation. So, I am going to start 
                investigating whether or not their example work. If it doesn't, it might be easier to figure out why that doesn't work
                than what I have.  
            </p>
            <p> Night: Okay. So, it turns out that the AWS example is wrong. Or at least I cannot get it to work. I'm almost cerrtain I am 
                not doing anything wrong, but it's frustrating that this is why I won't be able to co-simulate. I'm just going to move on to 
                matmuls, I can move on to it today so at least I got something out of this. I'm not entirely sure how to test the HBM and the DRAM
                but I'll figure it out (assuming there are no mistakes in their examples for those). Dissapointment about the docs is not the worst
                thing though, because I'm unhappy enough about this to want to finish the 4-bit register matmul tonight and move on to the HBM one 
                tomorrow.   
            </p>
            <p> Later Night: Matmul seems to be working. This is the same minimal register based implementation that I had. Since I am no longer 
                doing co-simulation, I figure I will spend the rest of the night figuring out how to get waveforms out of the simulation. 
                To be honest, it is probably not going to be that hard to vibe-code something that allows me to visualise them. Anyway, 
                I should confirm that the matmul stuff is working. Not because I need to test the module, I know it works, but becuase I want to 
                make sure that I know the entire process of starting from a new project to getting something that runs. 
            </p>
            <p> Even Later Night: Register based matmul works. I am using OCL to load in the matrices one element at a time. Since the 
                data bus size is 64 bits though I can load in 16 elements at a time. I'm not going to make this change though becuase
                I will never actually use OCL to load in the matrices. I'm going to spend the first half of tomorrow on the waveforms, 
                and then move on to HBM. I believe that HBM will be the hardest part of this because it also requires me to use PCIM/PCIS 
                for loading data, and the HBM monitor IO. Once this is all in order, getting SmolLM to run is just putting everything 
                together. Integration hell is real though so I don't want to get ahead of myself.
                
                P.S. I should start putting timestamps instead of putting evening, night, etc.
            </p>
        </article>

        <article class="blog-post">
            <div class="date">June 22, 2025</div>
            <p> Night: I forgot to update this with what I've been doing, but I spent a long time trying to figure out how to get waveforms. 
                Waveforms were a great way for me to debug stuff, so I wanted to get it to work. I couldn't. I just can't get Vivado to open.
                I'm generating the waveform files, I just can't get it to open. So, I turned to python and of course there is a package
                that allows me to open wdb files, which I can then use to generate images for myself. But it's not ideal. BUT, I'm much closer
                to getting co-simulation to work. I've been stuck on some imports that I don't know how to fix yet, but I imagine it won't 
                take me that long. Once this is done, I can finally move on to the actual matmul.
            </p>
            <p> Later Night: I'm at a little bit of a loss for how to run this co-simulation stuff. But, I think I will spend one more day on it. 
                If I can get it to work, then that is well and good. If I can't, I can always just test everything in SV, so it's okay. 
                So, if I can't get this to work by tomorrow, I'll just implement the 4-bit matmul using registers. Then, I will do it using 
                HBM, (there is also DRAM which I can look at using). Then, from there to LLM should be hard but straightforward.
            </p>
        </article>

        <article class="blog-post">
            <div class="date">June 19, 2025</div>
            <p> Afternoon: I realised that I forgot to fork the aws-fpga repository, so I did that and now most of everything I have done is on Github. 
                It isn't working though so there is still that. I don't even udnerstand what some of the errors I am getting mean, but hey, 
                one error at a time I guess. I've been trying to use Claude, Gemini and ChatGPT to help me understand what to do, 
                but the funny thing is that there is just so much information, and some of it is quite pooly documented, so both of us are confused. 
                Oh well, it's still going along. Conservatively, I could get this single register example to work by tomorrow and then from there 
                I can get a register based matrix multiply to work in a day. 
            </p>
            <p> Evening: It works! The module always worked I guess, but now I was able to run it through simultion with my own test. 
                There is still stuff that I haven't figured out, like how do I get the waveforms out. Also, there is something called
                Co-Simulation, where you test the C software and the SystemVerilog  hardware together. I don'tknow how to do that. 
                But, finally this is some measurable progress. I thought I could get this done by tomorrow, and since I am spending more time on it
                today, I should be able to figure the waveforms out, and then the co-simulation by tomorrow. From there matmul should be easy.
            </p>
        </article>

        <article class="blog-post">
            <div class="date">June 18, 2025</div>
            <p> I've been working on this stuff for a while now, and it might be one of the hardest things I've ever done. The documentation is quite bad, and the examples
                are so large and overwhelming. AWS has made quite a few changes between F1 and F2, so many resources are outdated. 
                I am also completely out of my depth with the SystemVerilog stuff they do in their examples. So, 
                I decided to start from the most minimal example. I have spent SO LONG on creating a counter (the counter wasn't the hard part,
                figuing out how to "wire" all the AXI stuff together was) and it's still not done. But, I can now elaborate it and run a simulation that turns it on. 
                This means that all my OCL connections (AXI stuff) are working. 
                I've set up the counter such that you can set a reset value, enable/disable it, and reset it to the reset value. All through AXI transactions. 
                Now, it's time to run a proper test on just the hardware, and then test it with the software.
                Once that's done, I can move on to working with the HBM.
            </p>
        </article>

        <article class="blog-post">
            <div class="date">June 10, 2025</div>
            <p> Morning: I didn't realise that setting everything up on AWS would take as long as it did. I tried all kinds of tools before going back to VSCode and Remote SSH. 
                I also spent some time looking at their provided examples, this seems like something I could do. Since I'm using the command line to run simulations and 
                stuff I'm not sure how things are going to look. I use the simulation for debugging stuff, and it seems like I can do that here too (I made like a counter
                module just to try things and it worked) but through like print statements? For whatever reason the Vivado GUI doesn't work so until I can figure that out, 
                I'm stuck with the CLI. 
            </p>

            <p> Evening: I didn't realise that I have no real way to show different "blogs" from the same day until I started writing this. I'll fix that at some point. 
                After spending more time understanding exactly how this F2 instance stuff works, I have to say that I can see why AWS is so big 
                (I know it's not because of FPGAs, but I mean this more in like a wow if they can do this everything they have must be insane.), and suffering through their 
                support was worth it. What they've done for me is basically turn the FPGA into my GPU. They allow you to write stuff in C/C++ to be able to communicate with
                the FPGA. They also allow you to write stuff in SystemVerilog which is run on the FPGA. So, for the final LLM stuff, I'll be able to accept inputs and tokenize
                in C++, which is such a lifesaver because I hadn't thought about how to do it on an FPGA. The FPGA just has to do the heavy lifting (which makes so much sense).
                Currently testing my Int4 matmul stuff on AWSs FPGA. Pretty cool.
            </p>
        </article>

        <article class="blog-post">
            <div class="date">June 9, 2025</div>
            <p> I've spent some time understanding how exactly the HBM works and how I can use it. Each board has 16GB of HBM 
                (which is way more than I need - a 135M parameter model in INT4 will use 67.5MB of space). You need to use the AXI protocol to communicate with it. 
                Also, according to the README it uses AXI3 at 450MHz (which seems slow? I remember when I built a PC like 7 years ago the DDR4 ram I had was at 3200 MHz).
                It has some AXI4 conversion layer which is at 250MHz. I'm not sure about why the discrepency, or what the differences are so I should spend some time reading 
                about this (they have modules for the conversion from AXI4 to AXI3 and for the HBM IP). 

                Sidenote: I'm using instance connect on EC2, and when I try to ctrl + shift + c firefox opens up the inspector. More reason to finish the multi clipboard.
            </p>
        </article>

        <article class="blog-post">
            <div class="date">June 8, 2025</div>
            <p> FINALLY! After what has felt like an eternity of back and forth with AWS support they finally unblocked by account. I've already set up my instance,
                and am figuring out how to get all teh Vivado stuff to work before I move to working on this full time. Not much progress has been made on the FPGALLM front
                so far, but things should go much faster now. I've also been looking into the other couple things and I have some cool stuff to share. I also had some 
                other stuff that I wanted to kind of explore so I'll probably write about that too. Not much else to say, just excited to finally be able to lock in on this. 
            </p>
        </article>

        <article class="blog-post">
            <div class="date">June 3, 2025</div>
            <p> I finally got access to the AWS account that has all the Nash credits, but for some reason I can't create any new EC2 instance. I also learned that 
                my understanding of how working on AWS will work was wrong. I don't need to create an F2 instance to be able to develop for FPGAs, I can use any instance
                with their FPGA AMI, and then the bitstream that is generated will run on an F2 instance. While waiting for a response from AWS support, I've decided to look
                at ways that I can parallelize the matrix multiplication. I've decided that I'm going to push the systolic array stuff back further than I initially expected, 
                to get it to run first before I make any big improvements. While I wait though, I think I'm going to try to process more than 1 multiply-and-accumulate operation
                in 1 clock cycle. I think I'm going to do this with like multiple accumulators that then get added together, but I'm not entirely sure. I also plan to work on 
                some of the smaller projects like the PC-iOS airdrop, and multi clipboard. 
            </p>
        </article>

        <article class="blog-post">
            <div class="date">May 28, 2025</div>
            <p>I have read that TPUs use systolic arrays for their operations, so I spent some time looking into what they are, how they are implemented, 
                and how I can use them for matrix multiplication. However, given that I haven't worked with SystemVerilog, I've implemented a simple, 2 for-loop implementation. 
                This is not efficient, but I figure if I start here I can work on implementing something faster later. I think the general flow I will follow is: 
                2 for loops => row * column in parallel => systolic array. One of the things I had a hard time with for the MNIST stuff was reading in weights from BRAM. 
                I imagine that is one of the most important things for me to do (figuring out how and where to read the weights from) so before making anything faster, 
                I should spend some time figuring out how this whole thing is going to be structured. Reading and using weights is what I should work on next.
                Based on some math that I did very quickly while working on this, I should be able to support upto 512 dimension matmul without overflowing
                (INT4 x INT4 => INT8 which has the range -64 to 63, 16-bit accumlator can have values from -2^15 to 2^15 - 1, so 2^15 / 64 = 512). I don't know if any matmul goes 
                beyond 512 dimensions for SmolLM, so will leave it at this for now. Going up to 32 bits requires changing literally 2 numbers so can make that change any time 
                (will require more resources etc. but I don't think I'm pushing the bounds of a $15000 board just yet). I remember that there are hazards and stuff that can go wrong 
                when actually running on hardware, so although most of what I am doing is focused around getting it to run in simulation, I should probably be mindful of this when measuring
                performance increase, otherwise I could set the clock speed to whatever I want and say that the performance is great. 

                <img src="../images/FPGALLM/Int4MatMul.png" alt="Simulation of Int4 MatMul">
                <div class="image-caption">Simulation of Int4 MatMul [[1, 2], [3, 4]] x [[5, 6], [7, -8]] => [[19, -10], [43, -14]] 
                    and [[7, -8], [-4, 0]] x [[-1, 3], [2, -5]] => [[-23, 61], [4, -12]]</div>
            </p>
        </article>

        <article class="blog-post">
            <div class="date">May 27, 2025</div>
            <p>I spent some time getting the Vitis suite installed. They don't have the boards used on EC2 F2 instances, so I picked whatever was closest, 
                and since it's been a while since I worked with SystemVerilog I decided a good place to start would probably be with the ALU.
                In ECE385 we learned about different kinds of adders (ripple carry, carry lookahead, carry select) but I'm just going to use the + operation because 
                Vivado will apparently implement the adder that is the most efficient (although if I'm not LUT or DSP contstrained might be interestint to experiment with different kinds).
                I also wrote a testbench for positive and negative numbers and it seems to work. I decided to implement an accumlator instead of an adder, because I can't think
                of a place where you would not be accumulating the results for the forward pass (although as I am writing this I wonder how the position embeddings are added for
                qunatized models, and those might require a regular addition operation). The next step is to implement a multiplier, and then I should have enough to check an int4 matmul.
                I was reading a little bit about how the forward pass happens for quantized models, and it seems like INT8 x INT8 => INT32, then the bias is added, 
                and the output is requantized. This is also something I'll have to implement later. 
                Again, while writing this I wonder if the accumulator is the best way to go about this or not. While performing a matmul, 
                one would multiply a row and a column entry-wise, and then add all of them together. Imagine I perform n multiplications in parallel (based on 
                how many multipliers I have), to add all of them to the same register using the accumulator as it is implemented right now, it would take me n clock cycles 
                (or n - 1 if it just starts out with the value of the first multiplication). Instead, I could create an adder, that 
                adds multiple numbers together, and then that output is what is stored in the register. Perhaps implementing an adder like this would be better, which with the + operation is easy.
                Also, since I will be performing the multiplication first, I would not be adding 4 bit numbers, because the output could be upto 8 bits (-8*-8 = 64).
                It's probably a good idea to implement a 4 bit matmul module first, see how that goes and decide what I need. The simulations are cool to look at anyway.

                <img src="../images/FPGALLM/AccumulatorAddition.png" alt="Accumulator Adder Block Diagram">
                <div class="image-caption">Simulation of accumulator adding [1, 7] => 0x1C (21)</div>

            </p>
        </article>

        <article class="blog-post">
            <div class="date">May 24, 2025</div>
            <p>I first worked on FPGAs + AI in my Digital Systems class where for my final project I ran a model for handwriting recognition on the FPGA we were given. 
                Since MNIST is a relatively easy task, a single linear linear layer performed well enough. I also cut some other corners by converting the inputs into binary, 
                which meant that I didn't need to perform any floating point multiplications. FPGAs don't seem ideal for floating point operations, 
                so it'll be interesting to see if there are any performace gains.
                From what I remember, it took 8 clock cycles for addition and 12-13 for multiplication (I'm not too worried about this because I think I can pipeline to process 12 inputs at a time). 
                I think I'm going to start with a very small model like SmolLM and integer quantization and play it by ear. For the MNIST
                stuff I wrote a Python script to convert the weights (only 1 weight matrix) into a text file with the binary representations of the weights, and loaded that into ROM.
                That worked okay for something with only 7840 parameters, but there's no way that'll work for 135M parameters. It'll also be interesting to 
                figure out tokenization, activation functions, different kinds of attention etc. I'll start by getting Vivado etc. set up and writing a module for INT4 multiplication. 
                From there I can work on matrix muliplications, and then fill in the rest. I should also check what board AWS EC2 F2 instances have, and work off those.</p>
        </article>

    </main>
</body>
</html> 